{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6573b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The codes in this notebook is partially based on (https://github.com/juliansester/nga/blob/main/Example%20SP500-Asian.ipynb).\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from GAD_util import *\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77bb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_parameters(x, \n",
    "                           iterations = 1000,\n",
    "                           initial_guess= [0.1,0.1,0,0,0.75],\n",
    "                           tolerance = 1e-15,\n",
    "                           Delta = 1/250.,\n",
    "                           method = 'COBYLA'):\n",
    "    x_0 = np.array(initial_guess) #Initial guess\n",
    "    eps = tolerance # Tolerance to avoid that fractions and log-expressions become inf or -inf\n",
    "    \n",
    "    #Definte the Log-Likelihood Function\n",
    "    def log_likelihood(param):\n",
    "        a_0 = param[0]\n",
    "        a_1 = param[1]\n",
    "        b_0 = param[2]\n",
    "        b_1 = param[3]\n",
    "        gamma = param[4]\n",
    "        constant = np.sqrt(2*np.pi*Delta)\n",
    "        l= [-np.log((a_0+a_1*np.maximum(x[i],0))**gamma*constant+eps)-(1/(2*Delta))*((x[i+1]-x[i]-(b_0+b_1*x[i])*Delta)/(a_0+a_1*np.maximum(x[i],0)+eps)**gamma)**2 for i in range(len(x)-1)]\n",
    "        return -np.mean(l) # Mean instead of sum to have smaller values\n",
    "    \n",
    "    a0,a1,b0,b1,gamma = minimize(log_likelihood,x_0,method=method,options={'maxiter': iterations,\n",
    "                                                                          'rhobeg':0.01},\n",
    "                bounds = [(eps,None),(eps,None),(None,None),(None,None),(eps,None)]).x\n",
    "    a0 = np.max([a0,eps])\n",
    "    a1 = np.max([a1,eps])\n",
    "    gamma = np.min([np.max([gamma,eps]),1.2]) # artificial lower/upper bound\n",
    "    return a0,a1,b0,b1,gamma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5254b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30\n",
    "dt = 1/250\n",
    "learning_rate = 0.005\n",
    "batch_size = 10000\n",
    "batch_num= 20\n",
    "epoch_num = 300\n",
    "T = dt * sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39c59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# # Stock tickers you're interested in\n",
    "# tickers = [\n",
    "#     'AAPL', 'MSFT', 'AMZN', 'GOOGL', 'BRK-B'\n",
    "# ]\n",
    "\n",
    "# # Define date range\n",
    "# start_date = '2008-09-26'\n",
    "# end_date = '2021-09-30'\n",
    "\n",
    "# # Fetching Close prices data\n",
    "# data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "\n",
    "# # Save to CSV for future reference\n",
    "# data.to_csv('stocks_close_prices_2008_2021.csv')\n",
    "\n",
    "\n",
    "# Load the dataset. Generated from the above code from yfinance.\n",
    "data = pd.read_csv(\"../Data/stocks_close_prices_2008_2021.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b58bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:31<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0\t64.50927734375\t64.50927734375\n",
      "a0_fix\t0.06747442236503542\t0.06747442236503542\n",
      "a1_fix\t0.15426034261762736\t0.15426034261762736\n",
      "b0_fix\t0.015307255745013263\t0.015307255745013263\n",
      "b1_fix\t0.28604643732012475\t0.28604643732012475\n",
      "gamma_fix\t1.2\t1.2\n",
      "a0_robust\t1e-15\t1.1713472722638891\n",
      "a1_robust\t0.15426034261762736\t1.1705841357901787\n",
      "b0_robust\t-0.013761652967194185\t0.24521661305958575\n",
      "b1_robust\t-0.1560054669357991\t0.6714145740929368\n",
      "gamma_robust\t0.17763848824856357\t1.2\n",
      "Fix train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      " \n",
      "Processing MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:35<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0\t143.90606689453125\t143.90606689453125\n",
      "a0_fix\t0.07526008675726047\t0.07526008675726047\n",
      "a1_fix\t0.11622482806788766\t0.11622482806788766\n",
      "b0_fix\t0.02224813120798452\t0.02224813120798452\n",
      "b1_fix\t0.2031023017354171\t0.2031023017354171\n",
      "gamma_fix\t1.2\t1.2\n",
      "a0_robust\t1e-15\t0.34645124078795325\n",
      "a1_robust\t0.10596797748510872\t1.352963788170841\n",
      "b0_robust\t-0.00571608112262144\t0.060765064311854494\n",
      "b1_robust\t-0.06539868920556884\t0.41485025843266077\n",
      "gamma_robust\t0.5000696075479992\t1.2\n",
      "Fix train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      " \n",
      "Processing AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:37<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0\t90.03050231933594\t90.03050231933594\n",
      "a0_fix\t0.10789576091790865\t0.10789576091790865\n",
      "a1_fix\t0.21872295610179698\t0.21872295610179698\n",
      "b0_fix\t0.010518479961781246\t0.010518479961781246\n",
      "b1_fix\t0.12967312106132894\t0.12967312106132894\n",
      "gamma_fix\t1.0091711476355227\t1.0091711476355227\n",
      "a0_robust\t1e-15\t0.8921314973414222\n",
      "a1_robust\t0.1754318552147132\t1.5674380800341674\n",
      "b0_robust\t-0.013150728747562627\t0.32954616445148277\n",
      "b1_robust\t-0.1190975571373096\t0.8017276829174065\n",
      "gamma_robust\t0.37305828862615203\t1.2\n",
      "Fix train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      " \n",
      "Processing GOOGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:41<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0\t60.50025177001953\t60.50025177001953\n",
      "a0_fix\t0.1109145611153623\t0.1109145611153623\n",
      "a1_fix\t0.32014512194417016\t0.32014512194417016\n",
      "b0_fix\t0.0038548804839231574\t0.0038548804839231574\n",
      "b1_fix\t0.10550705133490279\t0.10550705133490279\n",
      "gamma_fix\t0.9158212852191936\t0.9158212852191936\n",
      "a0_robust\t1e-15\t0.7019487616321505\n",
      "a1_robust\t0.13615342288254978\t1.7076161859621857\n",
      "b0_robust\t-0.012541790592237815\t0.08386929876758409\n",
      "b1_robust\t-0.08067327636191873\t0.4662031867550671\n",
      "gamma_robust\t0.42315388811131155\t1.2\n",
      "Fix train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      " \n",
      "Processing BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:40<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0\t193.1300048828125\t193.1300048828125\n",
      "a0_fix\t0.11065465690051735\t0.11065465690051735\n",
      "a1_fix\t0.2762809059595653\t0.2762809059595653\n",
      "b0_fix\t0.013188557242343782\t0.013188557242343782\n",
      "b1_fix\t0.03046389147642701\t0.03046389147642701\n",
      "gamma_fix\t0.8777524832562036\t0.8777524832562036\n",
      "a0_robust\t0.0959519171732222\t0.1710159216027636\n",
      "a1_robust\t0.0887268410123356\t1.0485521976368115\n",
      "b0_robust\t-0.0027169785611263334\t0.06703235521521311\n",
      "b1_robust\t-0.026459572768673226\t0.3505830370147668\n",
      "gamma_robust\t0.693507020789021\t1.191342188801752\n",
      "Fix train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Fix val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust train data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust test data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      "Robust val data shape: torch.Size([100000, 31]) tensor([10., 10., 10., 10., 10.])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for company_name in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'BRK-B']:\n",
    "    print(f\"Processing {company_name}...\")\n",
    "    S0 = data[company_name].values[2880]\n",
    "    comapny_price = data[company_name].values\n",
    "\n",
    "    #Create lists for the parameters\n",
    "    list_a0 = []\n",
    "    list_a1 = []\n",
    "    list_b0 = []\n",
    "    list_b1 = []\n",
    "    list_gamma = []\n",
    "    # list_a0_rescaled = []\n",
    "    # list_a1_rescaled = []\n",
    "    # list_b0_rescaled = []\n",
    "    # list_b1_rescaled = []\n",
    "    #Compute optimal parameters\n",
    "    for i in tqdm(np.arange(279,2880,100)): # until 9 March 2020\n",
    "        x = np.array(data[company_name].iloc[(i-250):i])\n",
    "        a0,a1,b0,b1,gamma = compute_max_parameters(x)\n",
    "        \n",
    "        list_a0 += [a0]\n",
    "        list_a1 += [a1]\n",
    "        list_b0 += [b0]\n",
    "        list_b1 += [b1]\n",
    "        list_gamma += [gamma]\n",
    "    a0_fix = [list_a0[26], list_a0[26]]\n",
    "    a1_fix = [list_a1[26], list_a1[26]]\n",
    "    b0_fix = [list_b0[26], list_b0[26]]\n",
    "    b1_fix = [list_b1[26], list_b1[26]]\n",
    "    gamma_fix = [list_gamma[26], list_gamma[26]]\n",
    "    a0_robust = [min(list_a0), max(list_a0)]\n",
    "    a1_robust = [min(list_a1), max(list_a1)]\n",
    "    b0_robust = [min(list_b0), max(list_b0)]\n",
    "    b1_robust = [min(list_b1), max(list_b1)]\n",
    "    gamma_robust = [min(list_gamma), max(list_gamma)]\n",
    "    parameters = {'S0':[S0,S0],'a0_fix': a0_fix, 'a1_fix': a1_fix, 'b0_fix': b0_fix, 'b1_fix': b1_fix, 'gamma_fix': gamma_fix, 'a0_robust': a0_robust, 'a1_robust': a1_robust, 'b0_robust': b0_robust, 'b1_robust': b1_robust, 'gamma_robust': gamma_robust}\n",
    "    for para_name, para_value in parameters.items():\n",
    "        print(f\"{para_name}\\t{para_value[0]}\\t{para_value[1]}\")\n",
    "\n",
    "    # Define the path generator function\n",
    "    generator_fix = path_generator_GAD(\n",
    "        time_steps=sequence_length,\n",
    "        S0=S0,\n",
    "        a0=a0_fix,\n",
    "        a1=a1_fix,\n",
    "        b0=b0_fix,\n",
    "        b1=b1_fix,\n",
    "        gamma=gamma_fix,\n",
    "        dt=dt\n",
    "    )\n",
    "    generator_robust = path_generator_GAD(\n",
    "        time_steps=sequence_length,\n",
    "        S0=S0,\n",
    "        a0=a0_robust,\n",
    "        a1=a1_robust,\n",
    "        b0=b0_robust,\n",
    "        b1=b1_robust,\n",
    "        gamma=gamma_robust,\n",
    "        dt=dt\n",
    "    )\n",
    "    # Generate the paths and save them\n",
    "    folder_path = f'../DATA/GAD_{company_name}'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    price_fix_train = generator_fix.generate(100000)/ S0 * 10\n",
    "    torch.save(price_fix_train, folder_path+'/GAD_fix_train.pt')\n",
    "    price_fix_test = generator_fix.generate(100000)/ S0 * 10\n",
    "    torch.save(price_fix_test, folder_path+'/GAD_fix_test.pt')\n",
    "    price_fix_val = generator_fix.generate(100000)/ S0 * 10\n",
    "    torch.save(price_fix_val, folder_path+'/GAD_fix_val.pt')\n",
    "    price_robust_train = generator_robust.generate(100000)/ S0 * 10\n",
    "    torch.save(price_robust_train, folder_path+'/GAD_robust_train.pt')\n",
    "    price_robust_test = generator_robust.generate(100000)/ S0 * 10\n",
    "    torch.save(price_robust_test, folder_path+'/GAD_robust_test.pt')\n",
    "    price_robust_val = generator_robust.generate(100000)/ S0 * 10\n",
    "    torch.save(price_robust_val, folder_path+'/GAD_robust_val.pt')\n",
    "    #check\n",
    "\n",
    "    print(\"Fix train data shape:\", price_fix_train.shape)\n",
    "    print(\"Fix test data shape:\", price_fix_test.shape)\n",
    "    print(\"Fix val data shape:\", price_fix_val.shape)\n",
    "    print(\"Robust train data shape:\", price_robust_train.shape)\n",
    "    print(\"Robust test data shape:\", price_robust_test.shape)\n",
    "    print(\"Robust val data shape:\", price_robust_val.shape)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1643f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AAPL for real test data...\n",
      "torch.Size([300, 31])\n",
      "Processing MSFT for real test data...\n",
      "torch.Size([300, 31])\n",
      "Processing AMZN for real test data...\n",
      "torch.Size([300, 31])\n",
      "Processing GOOGL for real test data...\n",
      "torch.Size([300, 31])\n",
      "Processing BRK-B for real test data...\n",
      "torch.Size([300, 31])\n"
     ]
    }
   ],
   "source": [
    "for company_name in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'BRK-B']:\n",
    "    print(f\"Processing {company_name} for real test data...\")\n",
    "    real_data_tensor = torch.Tensor(data[company_name])\n",
    "\n",
    "    price_real_test = torch.Tensor([])\n",
    "    for start in range(2880, 3180):\n",
    "        end = start + 31\n",
    "        part_normalized = real_data_tensor[start:end]/ real_data_tensor[start]*10\n",
    "        price_real_test = torch.cat((price_real_test, part_normalized.unsqueeze(0)), dim=0)\n",
    "\n",
    "    print(price_real_test.shape)\n",
    "    torch.save(price_real_test, f'../Data/GAD_{company_name}/GAD_real_test.pt')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
